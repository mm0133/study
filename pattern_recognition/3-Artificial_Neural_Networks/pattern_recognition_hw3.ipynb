{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pattern_recognition_hw3.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBHhwKy5N1Fs"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(123)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(123)\n",
        "\n",
        "learning_rate = 0.1\n",
        "training_epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "mnist_train = dsets.MNIST(root='./data',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(mnist_train, [54000, 6000])\n",
        "\n",
        "test_set = dsets.MNIST(root='./data',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(dataset=val_set, batch_size=6000)\n",
        "test_X= test_set.test_data.view(-1, 28 * 28).float().to(device)\n",
        "test_Y=test_set.test_labels.to(device)\n",
        "val_X, val_Y = next(iter(val_dataloader))\n",
        "val_X=val_X.view(-1, 28 * 28).float().to(device)\n",
        "val_Y=val_Y.to(device)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jp5YKoqN9tW"
      },
      "source": [
        "\n",
        "linear1 = torch.nn.Linear(784, 1024, bias=True)\n",
        "linear2 = torch.nn.Linear(1024, 10, bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "\n",
        "torch.nn.init.kaiming_uniform_(linear1.weight)\n",
        "torch.nn.init.kaiming_uniform_(linear2.weight)\n",
        "\n",
        "model = torch.nn.Sequential(linear1, relu, linear2).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "total_batch = len(data_loader)\n",
        "\n",
        "testacc_list=[]\n",
        "valacc_list=[]\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "  \n",
        "    for X, Y in data_loader:\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        prediction = model(val_X)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == val_Y\n",
        "        val_accuracy = correct_prediction.float().mean()*100\n",
        "\n",
        "        prediction = model(test_X)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == test_Y\n",
        "        test_accuracy = correct_prediction.float().mean()*100\n",
        "\n",
        "    testacc_list.append(test_accuracy)\n",
        "    valacc_list.append(val_accuracy)\n",
        "    print(f'Epoch:{epoch + 1:3d}, cost = {avg_cost:.9f}, test_acc:{test_accuracy}, val_acc:{val_accuracy}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OQPJSn38QqE"
      },
      "source": [
        "epoch_line=[i for i in range(1,training_epochs+1)]\n",
        "\n",
        "plt.plot(epoch_line, testacc_list,'r-',label='test_accuracy')\n",
        "plt.plot(epoch_line, valacc_list,'b-', label='val_accuracy')\n",
        "plt.xlabel(f'epoch(batch_size={batch_size})')\n",
        "plt.ylabel('accuracy(%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}